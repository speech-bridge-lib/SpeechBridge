#!/usr/bin/env python3
"""
SpeechRecognizer: –ú–æ–¥—É–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ —Å SSL fix
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç Google Speech Recognition –∏ Whisper —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
"""

# SSL Fix –¥–ª—è macOS –∏ multiprocessing fix - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–≤—ã–º –∏–º–ø–æ—Ä—Ç–æ–º
import os
import ssl

# Fix –¥–ª—è multiprocessing –Ω–∞ macOS (–æ—Å–æ–±–µ–Ω–Ω–æ —Å PyTorch/Whisper)
os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # –û—Ç–∫–ª—é—á–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º tokenizers
os.environ['OMP_NUM_THREADS'] = '1'            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º OpenMP –ø–æ—Ç–æ–∫–∏
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'  # Fallback –¥–ª—è Metal Performance Shaders

try:
    import certifi

    cert_path = certifi.where()
    os.environ['SSL_CERT_FILE'] = cert_path
    os.environ['SSL_CERT_DIR'] = os.path.dirname(cert_path)
    os.environ['REQUESTS_CA_BUNDLE'] = cert_path
    os.environ['CURL_CA_BUNDLE'] = cert_path

    # –°–æ–∑–¥–∞–µ–º SSL –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏
    context = ssl.create_default_context(cafile=cert_path)
    ssl._create_default_https_context = lambda: context
except Exception:
    pass

import logging
import tempfile
import time
from pathlib import Path
from typing import Optional, Dict, List

import speech_recognition as sr
from pydub import AudioSegment

# Whisper support
try:
    import whisper
    import torch
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False

import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent.parent))
from config import config


class SpeechRecognizer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""

    def __init__(self):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.recognizer = sr.Recognizer()

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 0.8
        self.recognizer.operation_timeout = 30  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º timeout
        self.recognizer.phrase_threshold = 0.3

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–≤–∏–∂–∫–æ–≤
        self.available_engines = self._test_engines_availability()

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        self.whisper_models = ["tiny", "base", "small", "medium", "large"]
        self.recognition_engines = ["whisper", "google", "sphinx"]
        
        # –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–º–æ–∂–Ω–æ –∏–∑–º–µ–Ω—è—Ç—å —á–µ—Ä–µ–∑ API)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º tiny –¥–ª—è Intel Mac –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.current_whisper_model = getattr(self.config, 'WHISPER_MODEL', 'tiny')
        self.preferred_engine = getattr(self.config, 'PREFERRED_RECOGNITION_ENGINE', 'whisper')
        
        self.logger.info(f"SpeechRecognizer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–≤–∏–∂–∫–∏: {list(self.available_engines.keys())}")
        self.logger.info(f"üéØ –¢–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: Whisper –º–æ–¥–µ–ª—å={self.current_whisper_model}, –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –¥–≤–∏–∂–æ–∫={self.preferred_engine}")

    def _test_engines_availability(self) -> Dict[str, bool]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥–≤–∏–∂–∫–æ–≤ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
        engines = {}

        # –¢–µ—Å—Ç Google Speech Recognition
        engines['google'] = self._test_google_sr()

        # –¢–µ—Å—Ç Whisper
        try:
            import whisper
            engines['whisper'] = True
            self.logger.debug("Whisper –¥–æ—Å—Ç—É–ø–µ–Ω")
        except ImportError:
            engines['whisper'] = False
            self.logger.debug("Whisper –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        # –¢–µ—Å—Ç PocketSphinx
        engines['sphinx'] = self._test_sphinx()

        return engines

    def _test_google_sr(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Google Speech Recognition API"""
        try:
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–æ–≤–æ–µ –∞—É–¥–∏–æ
            test_audio = AudioSegment.silent(duration=100)  # 0.1 —Å–µ–∫

            with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp_file:
                test_audio.export(tmp_file.name, format="wav",
                                  parameters=["-acodec", "pcm_s16le", "-ac", "1", "-ar", "16000"])

                with sr.AudioFile(tmp_file.name) as source:
                    audio_data = self.recognizer.record(source)

                # –ü–æ–ø—ã—Ç–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ API –≤—ã–∑–æ–≤–∞
                try:
                    self.recognizer.recognize_google(audio_data, language="en-US")
                    self.logger.info("‚úì Google Speech Recognition –¥–æ—Å—Ç—É–ø–µ–Ω")
                    return True
                except sr.UnknownValueError:
                    # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ç–∏—à–∏–Ω—ã - API –¥–æ—Å—Ç—É–ø–µ–Ω
                    self.logger.info("‚úì Google Speech Recognition –¥–æ—Å—Ç—É–ø–µ–Ω")
                    return True
                except sr.RequestError as e:
                    self.logger.warning(f"‚úó Google SR API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
                    return False

        except Exception as e:
            self.logger.warning(f"‚úó –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Google SR: {e}")
            return False

    def _test_sphinx(self) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ PocketSphinx"""
        try:
            test_audio = AudioSegment.silent(duration=100)
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmp_file:
                test_audio.export(tmp_file.name, format="wav")
                with sr.AudioFile(tmp_file.name) as source:
                    audio_data = self.recognizer.record(source)
                    self.recognizer.recognize_sphinx(audio_data)
                    self.logger.debug("‚úì Sphinx –¥–æ—Å—Ç—É–ø–µ–Ω")
                    return True
        except Exception:
            self.logger.debug("‚úó Sphinx –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False

    def transcribe_audio(self, audio_path: str, language: str = None) -> str:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞ —Å fallback —Å—Ç—Ä–∞—Ç–µ–≥–∏–µ–π –∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π

        Args:
            audio_path: –ø—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            language: –∫–æ–¥ —è–∑—ã–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)

        Returns:
            str: —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if language is None:
            language = self.config.SPEECH_LANGUAGE

        try:
            self.logger.debug(f"–ù–∞—á–∞–ª–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏–∑ {audio_path}")

            if not Path(audio_path).exists():
                raise FileNotFoundError(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")

            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
            processed_audio_path = self._preprocess_audio(audio_path)

            try:
                # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–±—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–≤–∏–∂–∫–∏
                result = None

                if self.available_engines.get('google', False):
                    result = self._transcribe_with_google_enhanced(processed_audio_path, language)
                    if result:
                        self.logger.info(f"Google SR —É—Å–ø–µ—à–Ω–æ: '{result[:50]}...'")
                        return result

                if self.available_engines.get('whisper', False):
                    result = self._transcribe_with_whisper(processed_audio_path, language)
                    if result:
                        self.logger.info(f"Whisper —É—Å–ø–µ—à–Ω–æ: '{result[:50]}...'")
                        return result

                if self.available_engines.get('sphinx', False):
                    result = self._try_sphinx(processed_audio_path, language)
                    if result:
                        self.logger.info(f"Sphinx —É—Å–ø–µ—à–Ω–æ: '{result[:50]}...'")
                        return result

                self.logger.warning("–ù–∏ –æ–¥–∏–Ω –¥–≤–∏–∂–æ–∫ –Ω–µ —Å–º–æ–≥ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å")
                return ""

            finally:
                # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                if processed_audio_path != audio_path and Path(processed_audio_path).exists():
                    Path(processed_audio_path).unlink()

        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏: {e}")
            return ""

    def _preprocess_audio(self, audio_path: str) -> str:
        """
        –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

        Returns:
            str: –ø—É—Ç—å –∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
        """
        try:
            audio = AudioSegment.from_file(audio_path)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            audio = audio.set_frame_rate(16000).set_channels(1)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
            if audio.dBFS < -30:
                # –£—Å–∏–ª–∏–≤–∞–µ–º —Ç–∏—Ö–æ–µ –∞—É–¥–∏–æ
                gain_needed = -20 - audio.dBFS
                audio = audio.apply_gain(min(gain_needed, 15))  # –ù–µ –±–æ–ª–µ–µ +15dB
                self.logger.debug(f"–£—Å–∏–ª–µ–Ω–æ –∞—É–¥–∏–æ –Ω–∞ {min(gain_needed, 15):.1f} dB")

            elif audio.dBFS > -6:
                # –ü–æ–Ω–∏–∂–∞–µ–º —Å–ª–∏—à–∫–æ–º –≥—Ä–æ–º–∫–æ–µ –∞—É–¥–∏–æ
                gain_needed = -12 - audio.dBFS
                audio = audio.apply_gain(gain_needed)
                self.logger.debug(f"–ü–æ–Ω–∏–∂–µ–Ω–æ –∞—É–¥–∏–æ –Ω–∞ {abs(gain_needed):.1f} dB")

            # –ë–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
            if len(audio) > 1000:  # –¢–æ–ª—å–∫–æ –¥–ª—è –∞—É–¥–∏–æ –¥–ª–∏–Ω–Ω–µ–µ 1 —Å–µ–∫—É–Ω–¥—ã
                audio = audio.high_pass_filter(80)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                audio.export(tmp_file.name, format="wav",
                             parameters=["-acodec", "pcm_s16le", "-ac", "1", "-ar", "16000"])
                return tmp_file.name

        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª: {e}")
            return audio_path

    def _transcribe_with_google_enhanced(self, audio_path: str, language: str) -> Optional[str]:
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ Google Speech Recognition —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        """
        max_attempts = 3

        for attempt in range(max_attempts):
            try:
                self.logger.debug(f"Google SR –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_attempts}")

                with sr.AudioFile(audio_path) as source:
                    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
                    self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                    audio_data = self.recognizer.record(source)

                # –†–∞–∑–ª–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ø—ã—Ç–æ–∫
                configs = [
                    {"language": language, "show_all": False},
                    {"language": language, "show_all": True},
                    {"language": "en-US", "show_all": False} if language != "en-US" else None
                ]

                for config in filter(None, configs):
                    try:
                        api_key = self.config.SPEECH_API_KEY

                        if api_key and api_key != "your_google_speech_api_key":
                            text = self.recognizer.recognize_google(
                                audio_data,
                                key=api_key,
                                **config
                            )
                        else:
                            text = self.recognizer.recognize_google(audio_data, **config)

                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                        if isinstance(text, dict) and 'alternative' in text:
                            if text['alternative'] and text['alternative'][0].get('transcript'):
                                return text['alternative'][0]['transcript'].strip()
                        elif isinstance(text, str) and text.strip():
                            return text.strip()

                    except sr.UnknownValueError:
                        continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
                    except sr.RequestError as e:
                        if "quota" in str(e).lower() or "limit" in str(e).lower():
                            self.logger.warning("Google SR: –ø—Ä–µ–≤—ã—à–µ–Ω—ã –ª–∏–º–∏—Ç—ã API")
                            return None
                        elif attempt < max_attempts - 1:
                            self.logger.warning(f"Google SR API –æ—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}): {e}")
                            time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
                            break
                        else:
                            self.logger.error(f"Google SR API –æ—à–∏–±–∫–∞: {e}")
                            return None

            except Exception as e:
                if attempt < max_attempts - 1:
                    self.logger.warning(f"Google SR –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ—É–¥–∞—á–Ω–∞: {e}")
                    time.sleep(1)
                else:
                    self.logger.error(f"Google SR –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                    return None

        return None

    def _transcribe_with_whisper(self, audio_path: str, language: str) -> Optional[str]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ OpenAI Whisper —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        """
        try:
            import whisper

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å (–∫—ç—à–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            model_name = getattr(self.config, 'WHISPER_MODEL', 'base')
            model = whisper.load_model(model_name)

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–¥ —è–∑—ã–∫–∞ –¥–ª—è Whisper
            whisper_language = self._convert_language_code_for_whisper(language)

            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –° –í–†–ï–ú–ï–ù–ù–´–ú–ò –ú–ï–¢–ö–ê–ú–ò
            result = model.transcribe(
                audio_path,
                language=whisper_language,
                task="transcribe",
                fp16=False,
                verbose=False,
                word_timestamps=True  # –ö–õ–Æ–ß–ï–í–û–ô –ü–ê–†–ê–ú–ï–¢–†!
            )

            text = result.get('text', '').strip()

            if text:
                # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                segments = result.get('segments', [])
                if segments:
                    self.logger.info(f"üïí Whisper: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏")
                    for i, seg in enumerate(segments[:3]):  # –ü–µ—Ä–≤—ã–µ 3 –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                        start = seg.get('start', 0)
                        end = seg.get('end', 0)
                        seg_text = seg.get('text', '')[:50]
                        self.logger.info(f"  –°–µ–≥–º–µ–Ω—Ç {i+1}: {start:.1f}-{end:.1f}—Å '{seg_text}...'")
                else:
                    self.logger.warning("‚ö†Ô∏è Whisper –Ω–µ –≤–µ—Ä–Ω—É–ª —Å–µ–≥–º–µ–Ω—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏")

                self.logger.info(f"‚úÖ Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–ª: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                return text

            return None

        except ImportError:
            self.logger.debug("Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            return None
        except Exception as e:
            self.logger.warning(f"Whisper –æ—à–∏–±–∫–∞: {e}")
            return None

    def transcribe_with_whisper_advanced(self, audio_path: str, language: str = "en", 
                                       model_size: str = "small") -> Optional[Dict]:
        """
        –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å Whisper —á–µ—Ä–µ–∑ subprocess –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∑–∞–≤–∏—Å–∞–Ω–∏—è
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –∏–∑ —É—Å–ø–µ—à–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Google Colab
        """
        try:
            import subprocess
            import json
            import tempfile
            
            self.logger.info(f"üéØ Whisper Subprocess: –º–æ–¥–µ–ª—å {model_size}, —è–∑—ã–∫ {language}")
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            with tempfile.NamedTemporaryFile(mode='w+', suffix='.json', delete=False) as tmp_file:
                result_file = tmp_file.name
            
            # –°–æ–∑–¥–∞–µ–º —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Whisper
            whisper_script = f"""
import whisper
import json
import sys
import os
import time

print("SUBPROCESS: –ù–∞—á–∞–ª–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è...")

# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è Intel Mac - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –º–Ω–æ–≥–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–Ω–æ—Å—Ç–∏
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['OPENBLAS_NUM_THREADS'] = '1'
os.environ['VECLIB_MAXIMUM_THREADS'] = '1'
os.environ['NUMEXPR_NUM_THREADS'] = '1'
os.environ['TOKENIZERS_PARALLELISM'] = 'false'
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
os.environ['TORCH_USE_CUDA_DSA'] = '0'
# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è Intel Mac
os.environ['OMP_MAX_ACTIVE_LEVELS'] = '1'
os.environ['PYTHONHASHSEED'] = '0'

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ multiprocessing –¥–ª—è macOS
try:
    import multiprocessing
    if hasattr(multiprocessing, 'set_start_method'):
        try:
            multiprocessing.set_start_method('spawn', force=True)
            print("SUBPROCESS: Multiprocessing —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ spawn —Ä–µ–∂–∏–º")
        except RuntimeError as e:
            print(f"SUBPROCESS: Multiprocessing —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {{e}}")
except Exception as e:
    print(f"SUBPROCESS: –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ multiprocessing: {{e}}")

try:
    print("SUBPROCESS: –ò–º–ø–æ—Ä—Ç torch...")
    import torch
    torch.set_num_threads(1)
    torch.set_num_interop_threads(1)
    # –û—Ç–∫–ª—é—á–∞–µ–º MPS –Ω–∞ Mac –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ 
    try:
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            if hasattr(torch.backends.mps, 'empty_cache'):
                torch.backends.mps.empty_cache()
            print("SUBPROCESS: MPS –æ—Ç–∫–ª—é—á–µ–Ω")
    except Exception as e:
        print(f"SUBPROCESS: MPS –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {{e}}")
    print("SUBPROCESS: Torch –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    print("SUBPROCESS: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_size}...")
    start_time = time.time()
    model = whisper.load_model('{model_size}', device='cpu')
    load_time = time.time() - start_time
    print(f"SUBPROCESS: –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {{load_time:.1f}}s")
    
    # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
    print("SUBPROCESS: –ù–∞—á–∞–ª–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è...")
    transcribe_start = time.time()
    result = model.transcribe(
        '{audio_path}',
        language='{self._convert_language_code_for_whisper(language)}',
        word_timestamps=True,
        verbose=False,
        fp16=False
    )
    transcribe_time = time.time() - transcribe_start
    print(f"SUBPROCESS: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {{transcribe_time:.1f}}s")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    print("SUBPROCESS: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞...")
    with open('{result_file}', 'w', encoding='utf-8') as f:
        json.dump({{
            'text': result.get('text', '').strip(),
            'segments': result.get('segments', []),
            'language': result.get('language', '{language}')
        }}, f, ensure_ascii=False, indent=2)
        
    print("SUCCESS")
    
except Exception as e:
    print(f"ERROR: {{e}}")
    import traceback
    traceback.print_exc()
    sys.exit(1)
"""
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–ø—Ç
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as script_file:
                script_file.write(whisper_script)
                script_path = script_file.name
            
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º Whisper –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                self.logger.info("üöÄ –ó–∞–ø—É—Å–∫ Whisper –≤ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –ø—Ä–æ—Ü–µ—Å—Å–µ...")
                self.logger.info(f"üìÑ –°–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞–Ω: {script_path}")
                self.logger.info(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤: {result_file}")
                
                import time
                start_time = time.time()
                
                try:
                    import sys
                    import os
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π Python –≤–º–µ—Å—Ç–æ miniforge3 –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
                    python_path = "/usr/local/bin/python3" if os.path.exists("/usr/local/bin/python3") else sys.executable
                    
                    self.logger.info(f"üêç –ò—Å–ø–æ–ª—å–∑—É–µ–º Python: {python_path}")
                    
                    result = subprocess.run([
                        python_path, script_path
                    ], capture_output=True, text=True, timeout=600)  # 10 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    
                    elapsed = time.time() - start_time
                    self.logger.info(f"‚è±Ô∏è Subprocess –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –∑–∞ {elapsed:.1f}s")
                    self.logger.info(f"üîç Return code: {result.returncode}")
                    self.logger.info(f"üì§ Stdout: {result.stdout[:200]}...")
                    if result.stderr:
                        self.logger.error(f"üì• Stderr: {result.stderr[:200]}...")
                        
                except subprocess.TimeoutExpired:
                    self.logger.error("‚è∞ Subprocess –ø—Ä–µ–≤—ã—Å–∏–ª —Ç–∞–π–º–∞—É—Ç 10 –º–∏–Ω—É—Ç!")
                    return None
                    
                if result.returncode == 0 and "SUCCESS" in result.stdout:
                    # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    with open(result_file, 'r', encoding='utf-8') as f:
                        whisper_result = json.load(f)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
                    segments = []
                    for segment in whisper_result.get("segments", []):
                        segments.append({
                            'start_time': segment['start'],
                            'end_time': segment['end'],
                            'text': segment['text'].strip()
                        })
                    
                    self.logger.info(f"üìä Whisper Subprocess: {len(segments)} –∏—Å—Ö–æ–¥–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                    
                    # –î–æ–±–∞–≤–∏–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                    total_whisper_duration = 0
                    if segments:
                        total_whisper_duration = segments[-1]['end_time'] - segments[0]['start_time']
                        self.logger.info(f"üïí Whisper —Ä–∞—Å–ø–æ–∑–Ω–∞–ª –∞—É–¥–∏–æ –æ—Ç {segments[0]['start_time']:.1f}s –¥–æ {segments[-1]['end_time']:.1f}s (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {total_whisper_duration:.1f}s)")
                        
                        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                        for i, seg in enumerate(segments[:3]):  # –ü–µ—Ä–≤—ã–µ 3
                            self.logger.info(f"  üéØ –°–µ–≥–º–µ–Ω—Ç {i+1}: {seg['start_time']:.1f}-{seg['end_time']:.1f}s '{seg['text'][:50]}...'")
                        if len(segments) > 6:
                            self.logger.info(f"  ... ({len(segments)-6} —Å—Ä–µ–¥–Ω–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤) ...")
                        for i, seg in enumerate(segments[-3:], len(segments)-2):  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 3
                            if i > 2: # –ò–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –µ—Å–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –º–∞–ª–æ
                                self.logger.info(f"  üéØ –°–µ–≥–º–µ–Ω—Ç {i}: {seg['start_time']:.1f}-{seg['end_time']:.1f}s '{seg['text'][:50]}...'")
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è –∏–∑ Colab)
                    sentence_segments = self._merge_segments_into_sentences(segments)
                    
                    return {
                        'text': whisper_result.get('text', '').strip(),
                        'segments': segments,
                        'sentences': sentence_segments,
                        'model': model_size,
                        'language': whisper_result.get('language', language),
                        'word_timestamps': True
                    }
                else:
                    self.logger.error(f"‚ùå Whisper subprocess failed: {result.stderr}")
                    return None
                    
            finally:
                # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                try:
                    os.unlink(script_path)
                    os.unlink(result_file)
                except:
                    pass
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ Whisper Advanced: {e}")
            return None
    
    def _merge_segments_into_sentences(self, segments: List[Dict], max_gap_seconds: float = 1.5) -> List[Dict]:
        """
        –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –ø–æ–ª–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
        –ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –∏–∑ —É—Å–ø–µ—à–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Google Colab
        """
        self.logger.debug(f"üìù –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–º–∞–∫—Å. –ø–∞—É–∑–∞ {max_gap_seconds}s)...")
        
        if not segments:
            return segments
        
        merged_segments = []
        current_sentence = None
        
        for i, segment in enumerate(segments):
            text = segment['text'].strip()
            
            if current_sentence is None:
                current_sentence = {
                    'start_time': segment['start_time'],
                    'end_time': segment['end_time'],
                    'text': text
                }
            else:
                gap = segment['start_time'] - current_sentence['end_time']
                
                # –£—Å–ª–æ–≤–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è (–ª–æ–≥–∏–∫–∞ –∏–∑ Colab)
                should_merge = (
                    gap <= max_gap_seconds and
                    not current_sentence['text'].rstrip().endswith(('.', '!', '?')) and
                    (not text or not text[0].isupper() or text.startswith(('and', 'or', 'but', 'so', 'because', 'that', 'which', 'who')))
                )
                
                if should_merge:
                    current_sentence['end_time'] = segment['end_time']
                    current_sentence['text'] = current_sentence['text'] + ' ' + text
                    self.logger.debug(f"   üîó –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç {i+1}: –ø–∞—É–∑–∞ {gap:.1f}s")
                else:
                    merged_segments.append(current_sentence)
                    current_sentence = {
                        'start_time': segment['start_time'],
                        'end_time': segment['end_time'],
                        'text': text
                    }
        
        if current_sentence:
            merged_segments.append(current_sentence)
        
        self.logger.info(f"‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ‚Üí {len(merged_segments)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
        return merged_segments

    def transcribe_audio_with_timestamps(self, audio_path: str, language: str = 'en-US') -> Optional[dict]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ (—Ç–æ–ª—å–∫–æ Whisper) —Å —Ç–∞–π–º–∞—É—Ç–æ–º
        
        Returns:
            dict: {'text': str, 'segments': [{'start': float, 'end': float, 'text': str}]}
        """
        try:
            import whisper
            import signal
            import os
            from pathlib import Path

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            if not Path(audio_path).exists():
                self.logger.error(f"–ê—É–¥–∏–æ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
                return None
                
            file_size = Path(audio_path).stat().st_size
            if file_size < 1000:  # –ú–µ–Ω–µ–µ 1KB
                self.logger.warning(f"–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π –∞—É–¥–∏–æ —Ñ–∞–π–ª: {file_size} –±–∞–π—Ç")
                return None

            self.logger.info(f"üéôÔ∏è Whisper timestamps: —Ñ–∞–π–ª {file_size} –±–∞–π—Ç")

            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–∞–π–º–∞—É—Ç–∞
            def timeout_handler(signum, frame):
                raise TimeoutError("Whisper –ø—Ä–µ–≤—ã—Å–∏–ª –ª–∏–º–∏—Ç –≤—Ä–µ–º–µ–Ω–∏ (180 —Å–µ–∫—É–Ω–¥)")

            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç 3 –º–∏–Ω—É—Ç—ã
            old_handler = signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(180)

            try:
                model_name = getattr(self.config, 'WHISPER_MODEL', 'base')
                self.logger.info(f"ü§ñ –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –º–æ–¥–µ–ª—å: {model_name}")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                model = whisper.load_model(model_name)
                self.logger.info("‚úÖ Whisper –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

                whisper_language = self._convert_language_code_for_whisper(language)

                # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏  
                self.logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å Whisper...")
                result = model.transcribe(
                    audio_path,
                    language=whisper_language,
                    task="transcribe",
                    fp16=False,
                    verbose=False,
                    word_timestamps=True,
                    no_speech_threshold=0.6,  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è —Ä–µ—á–∏
                    logprob_threshold=-1.0    # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
                )

                text = result.get('text', '').strip()
                segments = result.get('segments', [])
                
                self.logger.info(f"üéØ Whisper —Ä–µ–∑—É–ª—å—Ç–∞—Ç: —Ç–µ–∫—Å—Ç {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

                if text and segments:
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
                    formatted_segments = []
                    for seg in segments:
                        segment_text = seg.get('text', '').strip()
                        if segment_text:  # –¢–æ–ª—å–∫–æ –Ω–µ–ø—É—Å—Ç—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
                            formatted_segments.append({
                                'start': seg.get('start', 0),
                                'end': seg.get('end', 0), 
                                'text': segment_text
                            })

                    self.logger.info(f"üïí Whisper —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏: {len(formatted_segments)} –≤–∞–ª–∏–¥–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                    return {
                        'text': text,
                        'segments': formatted_segments
                    }

                self.logger.warning("Whisper –Ω–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª —Ä–µ—á—å –∏–ª–∏ —Å–µ–≥–º–µ–Ω—Ç—ã")
                return None

            finally:
                # –û—Ç–º–µ–Ω—è–µ–º —Ç–∞–π–º–∞—É—Ç
                signal.alarm(0)
                signal.signal(signal.SIGALRM, old_handler)

        except ImportError:
            self.logger.debug("Whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫")
            return None
        except TimeoutError as e:
            self.logger.error(f"‚è∞ Whisper —Ç–∞–π–º–∞—É—Ç: {e}")
            return None
        except Exception as e:
            self.logger.warning(f"Whisper –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –æ—à–∏–±–∫–∞: {e}")
            return None

    def _try_sphinx(self, audio_path: str, language: str) -> Optional[str]:
        """–ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ PocketSphinx"""
        try:
            with sr.AudioFile(audio_path) as source:
                audio_data = self.recognizer.record(source)
                text = self.recognizer.recognize_sphinx(audio_data)
                return text.strip() if text else None
        except Exception as e:
            self.logger.debug(f"Sphinx –æ—à–∏–±–∫–∞: {e}")
            return None

    def _convert_language_code_for_whisper(self, language: str) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∫–æ–¥–∞ —è–∑—ã–∫–∞ –¥–ª—è Whisper"""
        language_map = {
            'en-US': 'en', 'en-GB': 'en', 'ru-RU': 'ru', 'es-ES': 'es',
            'fr-FR': 'fr', 'de-DE': 'de', 'it-IT': 'it', 'pt-PT': 'pt',
            'zh-CN': 'zh', 'ja-JP': 'ja', 'ko-KR': 'ko'
        }

        if language in language_map:
            return language_map[language]

        base_language = language.split('-')[0].lower()
        return base_language if base_language in ['en', 'ru', 'es', 'fr', 'de', 'it', 'pt', 'zh', 'ja', 'ko'] else 'en'

    def transcribe_batch(self, audio_files: List[str], language: str = None) -> List[Dict]:
        """–ü–∞–∫–µ—Ç–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–≤"""
        results = []

        for i, audio_path in enumerate(audio_files):
            self.logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ {i + 1}/{len(audio_files)}: {Path(audio_path).name}")

            start_time = time.time()
            try:
                text = self.transcribe_audio(audio_path, language)
                processing_time = time.time() - start_time

                result = {
                    'file_path': audio_path,
                    'text': text,
                    'success': bool(text),
                    'processing_time': processing_time,
                    'error': None
                }

            except Exception as e:
                result = {
                    'file_path': audio_path,
                    'text': '',
                    'success': False,
                    'processing_time': time.time() - start_time,
                    'error': str(e)
                }
                self.logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {audio_path}: {e}")

            results.append(result)

        success_count = sum(1 for r in results if r['success'])
        self.logger.info(f"–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {success_count}/{len(audio_files)} —É—Å–ø–µ—à–Ω–æ")
        return results

    def get_supported_languages(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤"""
        return {
            'en-US': 'English (US)', 'en-GB': 'English (UK)', 'ru-RU': 'Russian',
            'es-ES': 'Spanish', 'fr-FR': 'French', 'de-DE': 'German',
            'it-IT': 'Italian', 'pt-PT': 'Portuguese', 'zh-CN': 'Chinese (Simplified)',
            'ja-JP': 'Japanese', 'ko-KR': 'Korean'
        }

    def test_recognition_engines(self) -> Dict[str, bool]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –¥–≤–∏–∂–∫–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        return self.available_engines.copy()

    def get_engine_status(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ç–∞—Ç—É—Å–∞ –¥–≤–∏–∂–∫–æ–≤"""
        status = {}

        for engine, available in self.available_engines.items():
            if available:
                status[engine] = "available"
            else:
                status[engine] = "unavailable"

        return status

    def get_available_models(self) -> Dict[str, List[str]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–≤–∏–∂–∫–∞"""
        return {
            'whisper': self.whisper_models,
            'google': ['standard'],  # Google Speech API –Ω–µ –∏–º–µ–µ—Ç –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏
            'sphinx': ['default']    # PocketSphinx –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å
        }
    
    def set_whisper_model(self, model: str) -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥–µ–ª–∏ Whisper"""
        if model not in self.whisper_models:
            self.logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å Whisper: {model}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {self.whisper_models}")
            return False
        
        self.current_whisper_model = model
        self.logger.info(f"üéØ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å Whisper: {model}")
        return True
    
    def set_preferred_engine(self, engine: str) -> bool:
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è"""
        if engine not in self.recognition_engines:
            self.logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–≤–∏–∂–æ–∫: {engine}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {self.recognition_engines}")
            return False
        
        if not self.available_engines.get(engine, False):
            self.logger.warning(f"–î–≤–∏–∂–æ–∫ {engine} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return False
        
        self.preferred_engine = engine
        self.logger.info(f"üéØ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –¥–≤–∏–∂–æ–∫: {engine}")
        return True
    
    def get_current_settings(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫"""
        return {
            'whisper_model': self.current_whisper_model,
            'preferred_engine': self.preferred_engine,
            'available_engines': list(self.available_engines.keys()),
            'available_whisper_models': self.whisper_models
        }
    
    def transcribe_with_engine(self, audio_path: str, engine: str = None, 
                             model: str = None, language: str = 'en-US') -> Optional[str]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –¥–≤–∏–∂–∫–∞ –∏ –º–æ–¥–µ–ª–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ –∏–ª–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π
        selected_engine = engine or self.preferred_engine
        
        # –î–ª—è Whisper –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ —Ç–µ–∫—É—â—É—é
        whisper_model = model or self.current_whisper_model
        
        self.logger.info(f"üéØ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: –¥–≤–∏–∂–æ–∫={selected_engine}, –º–æ–¥–µ–ª—å={whisper_model if selected_engine == 'whisper' else 'N/A'}")
        
        if selected_engine == 'whisper' and self.available_engines.get('whisper'):
            return self._transcribe_with_whisper(audio_path, language, whisper_model)
        elif selected_engine == 'google' and self.available_engines.get('google'):
            processed_audio = self._preprocess_audio(audio_path)
            result = self._transcribe_with_google_enhanced(processed_audio, language)
            if processed_audio != audio_path and os.path.exists(processed_audio):
                os.unlink(processed_audio)
            return result
        else:
            # Fallback –Ω–∞ –æ–±—ã—á–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            return self.transcribe_audio(audio_path, language)
    
    def _transcribe_with_whisper(self, audio_path: str, language: str, model: str = None) -> Optional[str]:
        """
        Subprocess –º–µ—Ç–æ–¥ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å Whisper –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∑–∞–≤–∏—Å–∞–Ω–∏—è –Ω–∞ Intel Mac
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–ª–∏ —Ç–µ–∫—É—â—É—é
            model_name = model or self.current_whisper_model
            
            self.logger.info(f"üéØ Whisper Subprocess: –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {model_name}")
            
            # –í—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—ã–π subprocess –º–µ—Ç–æ–¥
            result = self.transcribe_with_whisper_advanced(audio_path, language, model_name)
            
            if result and result.get('text'):
                return result['text']
                
            return None
            
            text = result.get('text', '').strip()
            
            if text:
                segments = result.get('segments', [])
                self.logger.info(f"‚úÖ Whisper {model_name}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                return text
            
            return None
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ Whisper {model_name}: {e}")
            return None


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
    print("=== –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ SpeechRecognizer ===")

    recognizer = SpeechRecognizer()
    print("SpeechRecognizer –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    # –°—Ç–∞—Ç—É—Å –¥–≤–∏–∂–∫–æ–≤
    status = recognizer.get_engine_status()
    print(f"–°—Ç–∞—Ç—É—Å –¥–≤–∏–∂–∫–æ–≤: {status}")

    # –¢–µ—Å—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —è–∑—ã–∫–æ–≤
    languages = recognizer.get_supported_languages()
    print(f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —è–∑—ã–∫–∏: {list(languages.keys())}")

    # –¢–µ—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º —Ñ–∞–π–ª–æ–º
    test_file = "test.wav"
    if Path(test_file).exists():
        result = recognizer.transcribe_audio(test_file)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: '{result}'")
    else:
        print(f"–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª {test_file}")